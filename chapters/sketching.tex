\chapter{Sketching}

Based on \cite{Avron-FasterRandomizedInfeasibleIPMs} we will use sketching to determine a preconditioner for \(\mat{A} \mat{D}^2 \mat{A}^T\) and iterative methods solve the normal equation. Furthermore, the solution gained by directly evaluating \cref{s-from-normal,x-from-normal} is perturbed to ensure any inaccuracies in \(\Delta\vek{y}\) only affect the last line of \cref{newton-system}.

%TODO Rename \vek{x} to \vek{s} because it is in the set Ss

\begin{definition} \label{def:oblivious-subspace-embedding}
A probability distribution over matrices \(\mat{W} \in \R^{w \times n}\) is a \((d, \e, \delta)\)-oblivious subspace embedding (OSE) if, for any \(d\)-dimensional subspace \(S \subset \R^n\) 
\[ \Probability \Paren{ \max_{x \in S, \norm{x} = 1} \Abs{ \norm{\mat{W}\vek{x}}^2 - 1} > \e } < \delta. \]
If \(\Abs{ \norm{\mat{W}\vek{x}}^2 - 1} \leq \e\) for all \(\vek{x} \in S\) with \(\norm{\vek{x}} = 1\) then \(\mat{W}\) satisfies the OSE property for \(S\).
\end{definition}

\begin{theorem}
The OSE property can be equivalently stated as
\[ (1-\e) \Norm{\vek{x}}_2^2 \leq \Norm{\mat{W}\vek{x}}_2^2 \leq (1+\e) \Norm{\vek{x}}_2^2 \quad \forall \vek{x} \in S. \label{ose-inequality} \]

If the subspace is written as \(S = \set{ \mat{U}\vek{z} | \vek{z} \in \R^d }\) for some matrix \(\mat{U} \in \R^{n \times d}\) with orthonormal columns, then the OSE property for \(S\) is equivalent to
\[ \Norm{(\mat{W}\mat{U})^T (\mat{W} \mat{U}) - \mat{U}^T \mat{U}}_2 \leq \e \] 
\end{theorem}
\begin{proof}
First, we note that the OSE property is equivalent to \((1-\e) \leq \norm{\mat{W}\mat{x}}^2 \leq (1+\e)\) for all \(\vek{x} \in S\) with \(\norm{\vek{x}} = 1\).
This implies that the OSE property is equivalent to
\[     (1-\e) \leq \Norm{\mat{W}\frac{\vek{x}}{\norm{\vek{x}}}}^2 \leq (1+\e)
  \iff (1-\e)\norm{\vek{x}}^2 \leq \Norm{\mat{W}\vek{x}}^2 \leq (1+\e)\norm{\vek{x}}
\]
for all \(\vek{x} \in S\).

Next, consider that the 2-norm of a matrix is its largest singular value and that the singular values of a symmetric matrix are the absolute values of its eigenvalues. 
Because the maximum and minimum eigenvalues are the maximum and minimum values of the Rayleigh quotient we get
\begin{align*}
  \Norm{(\mat{W}\mat{U})^T (\mat{W} \mat{U}) - \mat{U}^T \mat{U}}_2
  &= \max_{\vek{z} \in \R^d, \norm{\vek{z}}=1} \Abs{\vek{z}^T \Paren{(\mat{W}\mat{U})^T (\mat{W} \mat{U}) - \mat{U}^T \mat{U}} \vek{z}} \\
  &= \max_{\vek{z} \in \R^d, \norm{\vek{z}}=1} \Abs{(\mat{U}\vek{z})^T \Paren{\mat{W}^T \mat{W} - \mat{I}} \mat{U}\vek{z}} \\
  &= \max_{\vek{x} \in S, \norm{\vek{x}}=1} \Abs{\vek{x}^T \mat{W}^T \mat{W} \vek{x} - \vek{x}^T \vek{x}} \\
  &= \max_{\vek{x} \in \R^d, \norm{\vek{x}}=1} \Abs{\norm{\mat{W}\vek{x}}^2 - \norm{\vek{x}}^2} \\
  &= \max_{\vek{x} \in \R^d, \norm{\vek{x}}=1} \Abs{\norm{\mat{W}\vek{x}}^2 - 1}
\end{align*}
so \(\norm{(\mat{W}\mat{U})^T (\mat{W}\mat{U}) - \mat{U}^T \mat{U}} \leq \e\) if and only if \(\mat{W}\) satisfies the OSE property.
\end{proof}

These OSEs not only exist there are even ensembles of sparse matrices that form such an OSE.
The following sparse OSE result is taken from \cite{Cohen-NearlyTightObliviousSubspaceEmbeddings}.
\Textcite{Avron-FasterRandomizedInfeasibleIPMs} use the sketching result from \cite{Cohen-OptimalApproximateMatrixProduct} but for simplicity we replaced it by a simpler one giving the same complexity guarantees in the end(?).

\begin{definition}
A \emph{sparse embedding matrix} \(\mat{W} \in \R^{w \times n}\) is constructed in the following way:
For each column \(s\) entries are sampled randomly without replacement and for each such entry its value is randomly drawn from \(\{ - \frac{1}{\sqrt{s}}, \frac{1}{\sqrt{s}} \}\).
All other entries of \(\mat{W}\) are set to zero.
This defines a probability distribution over \(\R^{w \times n}\) where each sampled matrix has exactly \(s \cdot w\) nonzero entries.
\end{definition}

\begin{theorem}[Theorem 4.2 in \cite{Cohen-NearlyTightObliviousSubspaceEmbeddings}]  \label{thm:sparse-ose}
For any \(B > 2, \ \delta < 1/2, \ \e < 1/2\) there are
\[ w = O \Paren{\frac{B d \log(d/\delta)}{\e^2}} \quad \text{and} \quad s = O \Paren{\frac{\log_B(d/\delta)}{\e}}\]
such that the sparse embedding matrices form a \((d, \e, \delta)\)-OSE.
\end{theorem}

Such an ensemble of sketching matrices is used to construct a preconditioner for \(\mat{A}^T \mat{D}^2 \mat{A}\) in the form of a matrix \(\mat{Q} \in \R^{m \times m}\) such that
\( \mat{Q}^{-T} \mat{A}^T \mat{D}^2 \mat{A} \mat{Q}^{-1} \approx \mat{I}_m \).
Instead of solving the normal equation we then solve
\( \mat{Q}^{-T} \mat{A}^T \mat{D}^2 \mat{A} \mat{Q}^{-1} \vek{v} = \mat{Q}^{-T} \vek{p} \)
using an efficient iterative solver and \(\Delta\vek{y} = \mat{Q}^{-1} \vek{v}\).

Inspired by \textcite{Avron-FasterRandomizedInfeasibleIPMs} we use a QR decomposition of the sketched matrix \((\mat{A}\mat{D})^T\).
The set \(S = \set{ (\mat{A}\mat{D})^T \vek{z} | \vek{z} \in \R^m}\) is a \(m\)-dimensional subspace of \(\R^n\) assuming that \(\mat{A}\) has full row rank.
By \cref{thm:sparse-ose} there are
\[ w = O \Paren{ \frac{m \log(m/\delta)}{\e^2} } \quad \text{and} \quad s = O \Paren{ \frac{\log(m/\delta)}{\e} }\]
(using a fixed \(B > 2\)) such that \(\mat{W} \in \R^{w \times n}\) drawn from the corresponding probability distribution of sparse embedding matrices satisfies
\begin{equation}
  (1-\e) \norm{(\mat{A}\mat{D})^T \vek{z}}_2^2 \leq \norm{\mat{W}(\mat{A}\mat{D})^T \vek{z}}_2^2 \leq (1+\e)\norm{(\mat{A}\mat{D})^T \vek{z}}_2^2 \quad \forall \vek{z} \in \R^m
\end{equation}
with high probability \(1 - \delta\).